{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372416bb-b3ed-4b70-b476-8f13b81cc641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tkinter as tk\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "import torch\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize MTCNN and InceptionResnetV1 for face detection and embedding extraction\n",
    "mtcnn = MTCNN(keep_all=True)\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "# IP camera settings\n",
    "URL = \"rtsp://admin:A+0537239895a@192.168.0.108:554/live\"\n",
    "cap = cv2.VideoCapture(URL)\n",
    "\n",
    "# Set resolution for the IP camera\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "# Initialize zoom level\n",
    "zoom_level = 1.0\n",
    "\n",
    "# Database connection function\n",
    "def connect_to_db():\n",
    "    try:\n",
    "        return mysql.connector.connect(\n",
    "            host=\"127.0.0.1\",\n",
    "            user=\"user\",\n",
    "            password=\"user\",\n",
    "            database=\"fr\",\n",
    "            port=3306\n",
    "        )\n",
    "    except Error as e:\n",
    "        print(f\"Error connecting to database: {e}\")\n",
    "        return None\n",
    "\n",
    "# Connect to the database\n",
    "db = connect_to_db()\n",
    "if db is None:\n",
    "    print(\"Failed to connect to database. Exiting.\")\n",
    "    exit(1)\n",
    "cursor = db.cursor()\n",
    "\n",
    "# Function to load known faces from the personal table\n",
    "def load_known_faces():\n",
    "    known_embeddings = []\n",
    "    known_ids = []\n",
    "    try:\n",
    "        cursor.execute(\"SELECT personal_ID, embedding FROM personal\")\n",
    "        records = cursor.fetchall()\n",
    "        for row in records:\n",
    "            personal_id = row[0]\n",
    "            embedding = pickle.loads(row[1])  # Load serialized embeddings\n",
    "            known_ids.append(personal_id)\n",
    "            known_embeddings.append(torch.tensor(embedding))  # Convert to tensor\n",
    "        print(f\"Loaded {len(known_ids)} known embeddings from the database.\")\n",
    "    except Error as e:\n",
    "        print(f\"Error loading embeddings from database: {e}\")\n",
    "    return known_embeddings, known_ids\n",
    "\n",
    "# Function to save a new person across three tables\n",
    "def save_new_person_to_db(user_id, name, image_name, embedding):\n",
    "    try:\n",
    "        now = datetime.now()\n",
    "        date = now.date()\n",
    "        time = now.time()\n",
    "        serialized_embedding = pickle.dumps(embedding.numpy())\n",
    "        \n",
    "        # Insert into 'personal' table (ID auto-generated)\n",
    "        cursor.execute(\"INSERT INTO personal (personal_ID, name, embedding) VALUES (%s, %s, %s)\", \n",
    "                       (user_id, name, serialized_embedding))\n",
    "        \n",
    "        # Insert into 'image' table\n",
    "        cursor.execute(\"INSERT INTO image (personal_ID, image_name) VALUES (%s, %s)\", \n",
    "                       (user_id, image_name))\n",
    "        \n",
    "        # Insert into 'attendance' table\n",
    "        cursor.execute(\"INSERT INTO attendance (personal_ID, date, time) VALUES (%s, %s, %s)\", \n",
    "                       (user_id, date, time))\n",
    "        \n",
    "        db.commit()\n",
    "        print(f\"Saved new person with ID: {user_id}\")\n",
    "    except Error as e:\n",
    "        print(f\"Error saving new person to database: {e}\")\n",
    "\n",
    "# Function to generate a unique ID for new users\n",
    "def generate_unique_id():\n",
    "    try:\n",
    "        cursor.execute(\"SELECT MAX(CAST(personal_ID AS UNSIGNED)) FROM personal\")  # Ensure ID is treated as an integer\n",
    "        result = cursor.fetchone()[0]\n",
    "        if result is None:\n",
    "            return \"001\"  # Start from ID 001 if there are no entries\n",
    "        else:\n",
    "            return f\"{int(result) + 1:03d}\"  # Increment by 1 and format as a 3-digit number\n",
    "    except Error as e:\n",
    "        print(f\"Error generating unique ID: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to zoom into the frame\n",
    "def zoom_frame(frame, zoom_factor):\n",
    "    height, width, _ = frame.shape\n",
    "    center_x, center_y = width // 2, height // 2\n",
    "\n",
    "    # Calculate the bounding box for the zoom\n",
    "    box_width, box_height = int(width / zoom_factor), int(height / zoom_factor)\n",
    "    x1, y1 = center_x - box_width // 2, center_y - box_height // 2\n",
    "    x2, y2 = center_x + box_width // 2, center_y + box_height // 2\n",
    "\n",
    "    # Crop and resize back to original dimensions\n",
    "    cropped_frame = frame[y1:y2, x1:x2]\n",
    "    zoomed_frame = cv2.resize(cropped_frame, (width, height))\n",
    "    return zoomed_frame\n",
    "\n",
    "# Function to recognize faces and take action\n",
    "def recognize_and_capture():\n",
    "    global zoom_level  # Allow zoom_level to be adjusted dynamically\n",
    "    folder_path = Path('.')  # Save images in the current environment instead of the desktop\n",
    "    recognition_threshold = 0.8  # Increased threshold to make recognition less strict\n",
    "    known_embeddings, known_ids = load_known_faces()\n",
    "\n",
    "    if len(known_ids) == 0:\n",
    "        # If no embeddings are loaded, take a capture immediately\n",
    "        print(\"No known embeddings found. Capturing a new face immediately...\")\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture video frame.\")\n",
    "            return\n",
    "        frame = zoom_frame(frame, zoom_level)  # Apply zoom\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))  # Convert frame to PIL image\n",
    "        faces = mtcnn(img)\n",
    "        if faces is not None:\n",
    "            embeddings = model(faces).detach()\n",
    "            new_person_id = generate_unique_id()\n",
    "            image_count = 0\n",
    "            captured_images = []\n",
    "            while image_count < 3:\n",
    "                image_name = f\"user_{new_person_id}_capture_{image_count+1}.jpg\"\n",
    "                image_path = folder_path / image_name\n",
    "                cv2.imwrite(str(image_path), frame)\n",
    "                save_new_person_to_db(new_person_id, f\"Person {new_person_id}\", image_name, embeddings[0])\n",
    "                captured_images.append(image_path)\n",
    "                image_count += 1\n",
    "            print(f\"New person captured and saved with ID: {new_person_id}\")\n",
    "            # Reload known embeddings after capturing new person\n",
    "            known_embeddings, known_ids = load_known_faces()\n",
    "\n",
    "    # Continuous recognition loop\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture video frame.\")\n",
    "            break\n",
    "\n",
    "        frame = zoom_frame(frame, zoom_level)  # Apply zoom\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))  # Convert frame to PIL image\n",
    "        boxes, _ = mtcnn.detect(img)\n",
    "\n",
    "        if boxes is not None:\n",
    "            faces = mtcnn(img)\n",
    "            if faces is not None:\n",
    "                embeddings = model(faces).detach()  # Extract embeddings\n",
    "\n",
    "                # Loop through detected faces\n",
    "                for i, box in enumerate(boxes):\n",
    "                    x1, y1, x2, y2 = [int(i) for i in box]\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "                    # Compare the embedding of the current face with known embeddings\n",
    "                    distances = [torch.dist(embeddings[i], k_emb).item() for k_emb in known_embeddings]\n",
    "                    if distances:\n",
    "                        min_dist = min(distances)\n",
    "                        if min_dist < recognition_threshold:\n",
    "                            recognized_id = known_ids[distances.index(min_dist)]\n",
    "                            cv2.putText(frame, f\"ID: {recognized_id}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "                            print(f\"Recognized person with ID: {recognized_id}\")\n",
    "                        else:\n",
    "                            # Unknown person - capture new face\n",
    "                            print(\"Unknown face detected. Capturing new face...\")\n",
    "                            new_person_id = generate_unique_id()\n",
    "                            image_count = 0\n",
    "                            captured_images = []\n",
    "                            while image_count < 3:\n",
    "                                image_name = f\"user_{new_person_id}_capture_{image_count+1}.jpg\"\n",
    "                                image_path = folder_path / image_name\n",
    "                                cv2.imwrite(str(image_path), frame)\n",
    "                                save_new_person_to_db(new_person_id, f\"Person {new_person_id}\", image_name, embeddings[i])\n",
    "                                captured_images.append(image_path)\n",
    "                                image_count += 1\n",
    "                            print(f\"New person captured and saved with ID: {new_person_id}\")\n",
    "                            known_embeddings, known_ids = load_known_faces()  # Reload known faces\n",
    "\n",
    "        # Show the live video frame with bounding boxes in a smaller window\n",
    "        small_frame = cv2.resize(frame, (640, 360))\n",
    "        cv2.imshow('Face Recognition', small_frame)\n",
    "\n",
    "        # Check for zoom controls\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('+'):  # Zoom in\n",
    "            zoom_level = min(zoom_level + 0.1, 3.0)  # Cap zoom level at 3.0\n",
    "            print(f\"Zoomed In: {zoom_level:.1f}x\")\n",
    "        elif key == ord('-'):  # Zoom out\n",
    "            zoom_level = max(zoom_level - 0.1, 1.0)  # Minimum zoom level is 1.0\n",
    "            print(f\"Zoomed Out: {zoom_level:.1f}x\")\n",
    "        elif key == ord('q'):  # Quit the program\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to start the recognition process\n",
    "def start_recognition():\n",
    "    recognize_and_capture()\n",
    "\n",
    "# GUI with only the \"Start Recognition\" button\n",
    "def create_gui():\n",
    "    # Create the main window\n",
    "    window = tk.Tk()\n",
    "    window.title(\"Face Recognition System\")\n",
    "\n",
    "    # Set the window size and background color\n",
    "    window.geometry(\"400x300\")\n",
    "    window.configure(bg='#FEF4F0')  # Light background\n",
    "\n",
    "    # Start recognition button\n",
    "    tk.Button(window, text=\"Start Recognition\", command=start_recognition, bg='#6B5858', fg='white', width=25, font=('Instrument Serif', 11)).pack(pady=100)\n",
    "\n",
    "    window.mainloop()\n",
    "\n",
    "# Start the GUI\n",
    "create_gui()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
